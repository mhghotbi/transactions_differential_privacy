# Transaction SDC System - Default Configuration
# =============================================
# Statistical Disclosure Control for transaction data
# Copy this file and modify for your use case

[privacy]
# Bounded Contribution Settings
# =============================
# Limits how many transactions each card can contribute per cell (city, mcc, day)

# Method options:
# - 'transaction_weighted_percentile': Keep 99% of TRANSACTIONS (RECOMMENDED - minimal data loss)
# - 'percentile': Keep 99% of CELLS intact (can lose 50%+ transactions if distribution is skewed)
# - 'iqr': Statistical outlier detection (K = Q3 + 1.5*IQR)
# - 'fixed': Use a fixed K value
#
# RECOMMENDED: Use 'transaction_weighted_percentile' to minimize data loss
# This finds K such that (transactions_kept / total_transactions) >= percentile/100
# Example: percentile=99 means keep 99% of transactions (~1% data loss)
contribution_bound_method = transaction_weighted_percentile

# For 'iqr' method: multiplier for IQR (default 1.5 for standard outlier detection)
# K = ceil(Q3 + multiplier * IQR) where IQR = Q3 - Q1
contribution_bound_iqr_multiplier = 1.5

# For 'fixed' method: use this fixed value
contribution_bound_fixed = 5

# For 'percentile' method: use this percentile (e.g., 99)
# 99th percentile means 99% of card-cell combinations have <= K transactions
contribution_bound_percentile = 99

# Compute K per MCC for memory efficiency (recommended for large datasets)
# Set to false to compute K globally across all MCCs (uses more memory)
contribution_bound_per_group = true

# Suppression Settings
# ====================
# Suppress cells with noisy count below threshold
# Threshold: minimum noisy count to release (0 = no suppression)
suppression_threshold = 5

# Suppression method: 'flag' (add column), 'null' (set to NULL), 'value' (sentinel)
suppression_method = flag

# Sentinel value for suppressed cells (only used if method = value)
suppression_sentinel = -1

# Per-MCC Settings
# =================
# Each MCC is processed separately
# Percentile for computing per-MCC winsorization cap
# Example: 99.0 means use 99th percentile of transaction amounts per MCC
mcc_cap_percentile = 99.0

# Noise Settings (SDC)
# ====================
# Relative noise level for multiplicative jitter (0.15 = 15%)
noise_level = 0.15

# Jitter for derived unique_cards (0.05 = 5%)
cards_jitter = 0.05

# Jitter for derived total_amount (0.05 = 5%)
amount_jitter = 0.05

# Random seed for reproducible noise generation
noise_seed = 42

[data]
# Input data path (Parquet or CSV)
input_path = data/transactions.parquet

# Output path for protected data
output_path = output/protected/

# Path to city-province mapping CSV
city_province_path = data/city_province.csv

# Input format: parquet or csv
input_format = parquet

# Winsorization settings
# Percentile for automatic cap computation (0-100)
winsorize_percentile = 99.0
# Or set a fixed cap (uncomment to use):
# winsorize_cap = 100000000

# Date settings
date_column = transaction_date
date_format = %%Y-%%m-%%d
num_days = 30

[spark]
# Spark application name
app_name = TransactionSDC

# Spark master URL
# local[*] for local mode, spark://host:7077 for cluster
master = local[*]

# Memory settings
executor_memory = 4g
driver_memory = 2g

# Shuffle partitions
shuffle_partitions = 200

[columns]
# Column name mappings (source_column = standard_name)
# Modify if your data has different column names
transaction_id = transaction_id
amount = amount
transaction_date = transaction_date
card_number = card_number
acceptor_id = acceptor_id
acceptor_city = acceptor_city
mcc = mcc
